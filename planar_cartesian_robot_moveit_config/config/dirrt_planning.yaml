group_names_map:
  mg1:  planar_robot
  dirrt_paper:  planar_robot
  informed_rrt: planar_robot
  timebased: planar_robot
  mab_egreedy_ws: planar_robot
  mab_uniform:  planar_robot
  mab_uniform_volume: planar_robot
  mab_egreedy_5: planar_robot
  mab_egreedy_10: planar_robot
  mab_egreedy_20: planar_robot
  mab_ts: planar_robot
  mab_ts_bernoulli: planar_robot
  mab_ucb1: planar_robot
  mab_ucb1_bernoulli: planar_robot
  mab_egreedy_10_best: planar_robot
  mab_egreedy_10_bernoulli: planar_robot
  mab_egreedy_20_best: planar_robot
  mab_egreedy_20_bernoulli: planar_robot
  mab_egreedy_50_bernoulli: planar_robot
  mab_egreedy_adaptive_1: planar_robot
  mab_egreedy_adaptive_01: planar_robot
  mab_egreedy_adaptive_99: planar_robot
  mab_egreedy_adaptive_999: planar_robot

  # timebased:                     manipulator

default_planner_config: mg1

mg1:
  type: Multigoal
  max_distance: 2.0
  max_refine_time: 3.0     # time for refine solution
  utopia_tolerance: 0.003  # exit condition for early stop (cost< (1+utopia_tolerance) * distance)
  # max_refine_time: 3.0   # time for refine solution
  # utopia_tolerance: 0.05  # exit condition for early stop (cost< (1+utopia_tolerance) * distance)
  rewire_radius: 4.0
  extend: true
  local_bias: 0.25
  forgetting_factor: 0.999
  tube_radius: 0.02
  warp: false
  warp_once: true
  collision_distance: 0.001

timebased:
  type: TimeBasedMultigoal
  max_distance: 0.2
  max_refine_time: 1500.0
  extend: false
  local_bias: 0.0
  tube_radius: 0.02
  collision_distance: 0.001

informed_rrt:
  type: Multigoal
  max_distance: 2.0
  max_refine_time: 1500.0
  extend: true
  rewire_radius: 4.0
  local_bias: 0.0
  forgetting_factor: 0
  tube_radius: 0.01
  utopia_tolerance: 0.0000001
  collision_distance: 0.001
  informed: true
  mixed_strategy: false
  warp: false
  warp_once: false

dirrt_paper:
  type: Multigoal
  max_distance: 2.0
  extend: true
  rewire_radius: 4.0
  max_refine_time: 1500.0   # time for refine solution
  utopia_tolerance: 0.0000001  # exit condition for early stop (cost< (1+utopia_tolerance) * distance)
  # max_refine_time: 3.0   # time for refine solution
  # utopia_tolerance: 0.05  # exit condition for early stop (cost< (1+utopia_tolerance) * distance)
  #rewire_radius: 4.0
  local_bias: 0.5
  forgetting_factor: 0.999
  tube_radius: 0.02
  warp: false
  warp_once: false
  collision_distance: 0.0001
  mixed_strategy: true

mab_egreedy_5:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: eGreedy
  epsilon_coef: 0.05

mab_egreedy_10:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.1

mab_egreedy_20:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.2

mab_egreedy_adaptive_1:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_10
  egreedy_forgetting_factor: 0.01

mab_egreedy_adaptive_01:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_10
  egreedy_forgetting_factor: 0.001

mab_egreedy_adaptive_99:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_10
  egreedy_forgetting_factor: 0.99

mab_egreedy_adaptive_999:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_10
  egreedy_forgetting_factor: 0.999

mab_egreedy_10_best:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.1
  reward_fcn: BestCost

mab_egreedy_10_bernoulli:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.1
  reward_fcn: Bernoulli

mab_egreedy_20_best:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.2
  reward_fcn: BestCost

mab_egreedy_20_bernoulli:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.2
  reward_fcn: Bernoulli

mab_egreedy_50_bernoulli:
  type: Multigoal
  max_distance: 1.0
  inherit_from: mab_egreedy_5
  epsilon_coef: 0.5
  reward_fcn: Bernoulli

dirrt_egreedy:
  type: Multigoal
  max_distance: 1.0
  inherit_from: dirrt_paper
  policy_type: MultiArmedBandit
  policy_name: eGreedy

mab_egreedy_ws:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: eGreedy
  warm_start_reward: true

mab_ucb1:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: UCB1

mab_ucb1_bernoulli:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: UCB1
  reward_fcn: Bernoulli

mab_ts:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: Thomson

mab_ts_bernoulli:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: Thomson
  reward_fcn: Bernoulli

mab_uniform:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: PolicyUniformOnGoals

mab_uniform_volume:
  type: Multigoal
  max_distance: 1.0
  inherit_from: informed_rrt
  policy_type: MultiArmedBandit
  policy_name: PolicyUniformOnVolume
