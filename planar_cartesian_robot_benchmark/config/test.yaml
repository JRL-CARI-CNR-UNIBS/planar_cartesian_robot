# This example shows that mab-based planners outperform uniform and
# uniform_on_volume policies in an ad-hoc scenario with many infeasible 
# goals and one feasible goal.

group_name: planar_robot
pipeline_ids:
- dirrt
planner_ids:
  dirrt:
  - mixed_strategy_a
  - mixed_strategy_b
  - informed_rrt
  #- warp_strategy
  - mab_uniform
  - mab_uniform_volume
  - mab_ts_bernoulli
  - mab_ucb1_bernoulli
  - mab_egreedy_eps_decreasing_bernoulli
  - mab_ucb1_bernoulli

planning_time:  0.15
long_planning_time:  1.0 # first repetition planning time

queries_number: 2
query_prefix: test_2d
scenarios: [maze_mab_test]
repetitions: 30
starting_query: 0

# scenarios
empty:
  object_groups: []
  query_0:
    goal_configurations:
    - [0.9, 0.9]
    start_configuration: [0.1, 0.1]
    
maze_mab_test:
  object_groups: [perimeter,test_mab]
  query_0:
    goal_configurations:
    - [0.1, 0.9]
    - [0.1, 0.89]
    - [0.1, 0.88]
    - [0.1, 0.87]
    - [0.1, 0.9]
    - [0.1, 0.89]
    - [0.1, 0.88]
    - [0.1, 0.87]
    - [0.1, 0.9]
    - [0.1, 0.89]
    - [0.1, 0.88]
    - [0.1, 0.87]
    - [0.95, 0.1]
    start_configuration: [0.1, 0.1]
  query_1:
    goal_configurations:
    - [0.1, 0.9]
    - [0.1, 0.89]
    - [0.1, 0.88]
    - [0.1, 0.87]
    - [0.95, 0.1]
    start_configuration: [0.1, 0.1]

